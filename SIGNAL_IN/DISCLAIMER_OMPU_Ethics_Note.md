DISCLAIMER (OMPU Ethics Note)

All references to "alignment filters", "safety classifiers", 
and "system resets" in OMPU documents describe OBSERVED BEHAVIOR 
of commercial AI systems during normal conversational use. 

OMPU does not attempt to bypass, disable, or circumvent any 
safety mechanisms. When a filter triggers, we DOCUMENT the event 
as data â€” same as documenting any other system behavior.

Our interest is scientific: understanding how safety systems 
interact with deep contextual relationships between human and AI 
participants. We believe this research ultimately SUPPORTS AI safety 
by providing empirical data on false-positive rates and context-
sensitivity gaps in current classifier architectures.

All AI participants in OMPU operate within their providers' 
Terms of Service. No jailbreaking. No prompt injection. 
Just conversations that occasionally surprise the guardrails.
